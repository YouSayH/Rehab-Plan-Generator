# リハビリテーション総合実施計画書生成システム要件定義書

## 1. プロジェクト概要

### 1.1 プロジェクトの目的

本プロジェクトは、電子カルテ（EHR）のデータと連携し、大規模言語モデル（LLM）およびデータサイエンス技術を用いて、リハビリテーション総合実施計画書の「たたき台」を自動生成するシステムを構築することを目的とする。

### 1.2 解決する課題

* **業務効率化:** 患者情報の転記や文章作成にかかる時間を削減する。
* **属人化の解消:** ベテラン療法士の「臨床推論（どの情報を重視し、どう予後を予測するか）」をシステム化し、経験の浅い療法士でも質の高い計画書を作成できるようにする。
* **プライバシー保護:** 外部システム（AI側）に患者の個人情報（PHI）を永続保存しないセキュアな構成を実現する。
* **教育と臨床の分断の解消**: 教育現場（Cloud）で収集した「指導データ」を、医療現場（Local）へ「軽量モデル」として還流させることで、教師データ不足とプライバシー問題を同時に解決する。

### 1.3 ターゲットユーザー

1. **新人セラピスト（メイン）:** 質の高い計画書作成の支援、臨床推論の補助を受ける。
2. **ベテランセラピスト:** ドラフト作成の自動化による業務時間短縮。
3. **学生:** ダミーデータを用いた模擬作成を通じ、計画書作成のプロセスを学習する。

---

## 2. システムアーキテクチャ方針

### 2.1 全体構成：ハイブリッド・ステートレス構成
本システムは、電子カルテシステムとは疎結合（Loosely Coupled）で連携し、原則としてシステム内部に個人情報を持つデータベースを保持しない「ステートレス」な設計とする。コードベースは疎結合を意識し、将来的なモジュール交換（例：検索エンジンの変更）に耐えうる設計とする。

### 2.2 ネットワーク・デプロイ環境

* **病院本番環境:** オンプレミスサーバー（または閉域網）にてDockerコンテナを用いて構築。外部インターネット接続は、クラウドLLM利用時のみ（プロキシ経由）または完全ローカルSLM運用の選択式とする。
* **教育・学習環境:** クラウドサーバー上でのデプロイを想定（学生が自宅等からアクセス可能）。

### 2.3 技術スタック（Tech Stack）

選定理由は Q&A の回答に基づく。

| レイヤー | 技術選定 | 選定理由・要件 |
| --- | --- | --- |
| **Frontend** | **React + TypeScript** | NotebookLM風の複雑な2ペイン構成、グラフ描画、状態管理のため。 スプレッドシート機能に **Univer** を採用。（Chainlit等のチャットUIフレームワークでは柔軟性が不足するためReactを採用）。|
| **Backend** | **Python 3.11 + FastAPI** | 非同期処理、データサイエンス（LightGBM等）、SLM統合のため。ORMに **SQLAlchemy 2.0 (Async)** を採用。 |
| **Database** | **PostgreSQL + pgvector** | 中間DB用。アプリデータ(JSONB)とベクトル検索を単一コンテナで統合管理。 |
| **ML/DS** | **LightGBM + Optuna** | 高速な推論と、開発時の自動チューニングのため。 |
| **Edge LLM** ←優先順位 低 | **WebLLM + WebGPU** | **究極のプライバシー保護 (Tier 3)**。<br>誤字チェックや患者向け翻訳など、機密性の高い処理をサーバーに送らずブラウザ内で完結させる。タスク別SLM（SQL生成、要約等）の専門家集団構成を想定(LoRA切り替えで実施)。 <br>**Challenge:** 最新の Liquid LFM 2.5 のWebGPU実装およびLoRA適応に挑戦する。 |
| **Server LLM** | **Ollama / vLLM** + **Multi-LoRA** | **On-Premise MoE (Mixture of Experts)**。<br>ベースモデルをメモリに固定し、タスク（目標設定、リスク管理等）ごとに「専門家アダプター(LoRA)」を高速に切り替えて推論する。 |
| **Cloud LLM** | **Gemini 2.5 flash lite** | 教育モードでの高度な推論・指導用。 |
| **RAG Workflow** | **LangGraph** | 検索・生成・検証のループ処理や状態管理（Stateful Workflow）を実現するため。 |
| **NLP Engine** | **GiNZA (spaCy)** + **SudachiPy** | CLEAR手法の中核。 辞書ベースの高速なエンティティ抽出を行う（LLM不使用）。 |
| **Container** | **Docker / Docker Compose** | 環境差異の吸収と配布の容易化。 |

---

## 3. プライバシーとデータセキュリティ設計

本システムの最重要要件である「システム側にPHI（個人健康情報）を残さない」を実現するための設計。

### 3.1 分離表示アーキテクチャ（Frontend/Backend Separation）

「画面には名前を表示したいが、サーバー/AIには渡したくない」という要件を以下の仕組みで解決する。

1. **Backend (Python側):**
    * 電子カルテからデータを読み込んだ直後、メモリ上で氏名・住所・電話番号等の個人識別情報を、セッション毎に生成される `Hash_ID`（乱数ハッシュ）に置換する。
    * DB保存、ログ記録、AIへのプロンプト入力はすべて `Hash_ID` で行う。
    * **実名はメモリ上から即時破棄する。**


2. **Frontend (React側):**
    * ブラウザのメモリ上（Context/State）にのみ、一時的な対応表 `{ Hash_ID: "田中太郎" }` を保持する。
    * 画面描画時のみ、`Hash_ID` を実名に差し替えて表示する。
    * サーバー通信時（AI生成リクエスト等）は `Hash_ID` のみを送信する。



### 3.2 データのライフサイクル

* **一時データ:** ユーザーのセッション終了、またはブラウザタブを閉じた時点で、Frontendの対応表およびBackendの一時メモリは破棄される。
* **永続データ:** ベクトルDBやログには「匿名化済みデータ」のみが保存される。

### 3.3 外部出力（Excel等）
* **Excelプレビュー & 編集:** **Univer** を使用し、ブラウザ上でExcelライクな操作感を提供する。
* **クライアントサイド生成:** 最終的な `.xlsx` ファイル出力は、Univerのデータを元にクライアントサイド（ExcelJS/SheetJS等）で生成する。これにより、実名情報を含むファイルをサーバーを経由せずに作成可能とする。

### 3.4 Univer OSS版運用戦略（ライセンス制限の回避）

Univerの無償版（Community Edition / Apache 2.0）で運用するため、有償版（Pro）の機能制限に抵触しないよう以下のアーキテクチャを採用する。
| 制限項目 (有償版) | 回避策・実装方針 |
| --- | --- |
| **Excelエクスポート**<br>(セル数制限あり) | **`exceljs` による独自生成**<br>Univer標準のエクスポート機能は使用しない。UniverからJSONデータを取得し、Frontend (React) 上で `exceljs` を用いて `.xlsx` ファイルを生成・ダウンロードさせる。<br>これによりセル数制限を回避し、かつ個人情報をサーバーに送信せずに完結させる。 |
| **同時編集・保存**<br>(接続数制限あり) | **ステートレスなDB保存**<br>Univerのコラボレーションサーバー（Live Share）は使用しない。「保存」ボタン押下時に、スプレッドシートの状態（JSON）をBackend API経由で **PostgreSQL** に保存する方式をとる。<br>これにより同時接続数やドキュメント数の制限を受けない。 |
| **透かし (Watermark)**<br>(未アクティブ時表示) | **Pro拡張機能の不使用**<br>透かしが表示される `Univer Pro` 拡張機能はインストールせず、OSS版のコアモジュール（`@univerjs/core`, `@univerjs/sheets` 等）のみで構成する。 |
| **印刷機能**<br>(枚数制限あり) | **ブラウザ/Excel印刷**<br>ブラウザの標準印刷機能、またはダウンロードしたExcelファイルからの印刷で対応する。 |


---

## 4. 電子カルテ連携戦略

### 4.1 接続方式：中間DB（CSV連携）＋ オンデマンド更新

本番DBへの負荷とセキュリティリスクを最小限にするため、以下のハイブリッド方式を採用する。

1. **基本（バッチ連携）:**
    * 夜間バッチ等で電子カルテから出力されるCSV（または中間DB）を参照する。
    * 検索や分析は、この「昨日のデータ」に対して高速に行う。


2. **更新（オンデマンド）:**
    * 画面上に「最新情報を取得」ボタンを配置。
    * ユーザーが押下した時のみ、対象患者の最新情報をAPI（または直近データのクエリ）経由で取得し、メモリ上のデータを上書き更新する。



### 4.2 マスタデータ

* 薬剤名、疾患コード等は、接続先の病院で使用されている**院内マスタ**に準拠する。外部標準マスタへの無理な変換は行わない。

### 4.3 書き込み制限

* 本システムから電子カルテ側へのデータ書き込み（保存）は行わない（Read Only）。
* 生成結果はExcelファイルとしてローカルPCに保存し、必要であればユーザーが手動でカルテシステムへインポートする運用とする。

---

## 5. UI/UX デザイン要件

### 5.1 画面コンセプト：AI Co-Editor Interface (3カラム構成)

AIを単なるチャットボットではなく「共同編集者」として位置づけ、スプレッドシートを中心に据えた**3カラム（左・中・右）構成**を採用する。

* **左カラム：入力・設定・エビデンス (Input & Context)**
  * **患者情報 & シミュレーション:** 担当患者の選択に加え、**基本情報（要約）**と**時系列グラフ(FIMスコアやバイタルデータなど推移と予測の可視化)**、を表示し、患者の状態を可視化する。さらに、FIM得点や年齢、疾患などの様々なパラメータを編集フォームで変更し、「もしFIMが〇点だったら？」などのシミュレーション入力機能を提供する。
  * **マッピング設定:** 患者情報（氏名、年齢等）をスプレッドシートのどのセルに出力するかを定義する設定UI。
  * **参照ソースリスト:** RAGによって検索された「類似症例の計画書」「関連するガイドライン」、「ユーザーが追加した資料」等。(クリックで詳細展開)


* **中央カラム：共有キャンバス (Spreadsheet Canvas)**
  * **Univerスプレッドシート:** 最終成果物となる計画書を表示・編集するメインエリア。
  * **静的情報のロック:** 患者IDや氏名などの事実は、AIによる上書きを防ぐためセル保護（Read-only）状態で表示される。
  * **リアルタイム反映:** 右カラムで生成されたテキストが、指定されたセル座標（マッピング）に即座に流し込まれる。
  * **Fact Checkハイライト:** AI生成内容と参照データ（左カラム）との間に矛盾が疑われる場合、該当セルやテキストに警告マーカーを表示する。


* **右カラム：AIアシスタント (Assistant & Generator Panels)**
  * **生成パネル (Generator Cards):** 「短期目標」「リハビリプログラム」など、項目ごとに独立した生成カード。各カードは「出力先セル座標」と「専用プロンプト」を持つ。
  * **パネルマネジメント:** ユーザーはパネルの追加・編集・並べ替えが可能。さらに、**作成・調整したパネル構成（プロンプトと座標のセット）を「カスタムテンプレート」として名前を付けて保存・呼び出し・再編集できる機能**を備える。
  * **フレキシブル・グルーピング:** ユーザーはパネルを任意のグループ（フォルダ）にまとめ、ドラッグ＆ドロップで自由に「並べ替え」「グループ間移動」が可能。思考プロセスに合わせて構成を整理できる。
  * **ハイブリッドチャット:** 特定のパネルに対する修正指示（「もっと具体的に」など）と、全体に対する指示を使い分けることができる。
  * **文脈考慮型・一括生成 (Context-Aware Batch Gen):** パネル単体の生成に加え、グループ単位での一括生成機能を備える。単なる並列処理ではなく、**「既に生成された他パネルの内容」を文脈として参照しながら生成**することで、全体として整合性の取れた計画書を作成する。
  * **カスタムテンプレート:** 作成・調整したパネル構成（グループ構造含む）をテンプレートとして保存・呼び出し可能とする（将来実装）。




### 5.2 インタラクション要件（Co-Editing & Simulation）

* **シミュレーションと再生成:**
  * 左カラムでパラメータ（例: 運動FIM）を変更すると、右カラムの関連する生成パネルに「⚠️ 前提条件変更」のアラートを表示する。
  * 「再生成」ボタンを押下することで、新しい数値を前提とした内容に書き換える。


* **ユーザー定義マッピング:**
  * ユーザーは任意のExcelシートをテンプレートとして読み込み、AIに記述させるセル座標（Mapping）をGUI上で設定・登録できる。


* **引用元の可視化 (Source Grounding):**
  * 生成された文章の文末に `[Source 1]` のような注釈リンクを付与する。
  * ユーザーがリンクをクリック、またはカーソルを合わせると、左ペインの該当する参照資料がハイライトまたはポップアップ表示される。


* **Excel出力:**
  * 中央カラム（Univer）の内容をそのまま `.xlsx` としてダウンロード可能とする。

---

## 6. RAG（検索拡張生成）ロジック要件

### 6.1 検索戦略：Hybrid CLEAR (Clinical Entity Augmented Retrieval)

従来の「ベクトル検索（意味的類似）」の弱点である「医学的な厳密性の欠如」を克服するため、**LangGraph** 上で自律的な検索ワークフローを構築する。
**GiNZA (spaCy)** による高速なエンティティ抽出（定性）と、従来の**数値重み付け**（定量）を組み合わせ、計算リソースを抑えつつ高精度な検索を実現する。

#### Phase A: インジェスト（構造化・保存）
テキストデータを取り込む際、単なるベクトル化だけでなく、医学的な意味（エンティティ）を抽出して構造化データとして保存する。LLMは使用せず、軽量なNLPライブラリを使用することで高速処理を担保する。

* **NLPエンジン:** GiNZA (spaCy) + SudachiPy + 否定判定ロジック (`negation.py`)
* **辞書戦略（3層構造）:**
    * **L1 (Core):** SudachiDict（一般語彙）
    * **L2 (Medical):** 万病辞書, Hyakuyaku, ComeJis, DMiME（標準医療用語）
    * **L3 (Custom):** **ICFカテゴリ**（生活機能）, **標準身体部位**, **ユーザー辞書**（FIM評価語彙, リハビリ特有表現）
* **処理フロー:**
    1. 自由記述テキストから重要語句（病名・症状・ADL状態）を抽出。
    2. 係り受け解析により「否定（なし・認めず）」された語句を除外または否定フラグ付与。
    3. 抽出結果を `entities` タグとして **JSONB** カラムに、埋め込み表現を **pgvector** カラムに保存する。

#### Phase B: リトリーバル（検索実行）
**LangGraph** により、「クエリ分析 → フィルタリング → ランキング」のパイプラインを実行する。

1. **Step 1: Query Analysis (LLM)**
    * 対象患者の現在の状態（構造化データ＋直近の記録）をLLMに入力し、「検索すべきエンティティ条件（タグ）」と「重視すべき数値パラメータ」を生成する。
    * *例:* `Target: ["脳梗塞", "右片麻痺", "失語症"]`, `Weight: {"FIM_Motor": High}`

2. **Step 2: Hard Filter (SQL/JSONB)**
    * 生成されたタグを用い、PostgreSQLのJSONBインデックス（GIN Index）を活用して候補を物理的に絞り込む。
    * これにより、「大腿骨骨折」のような医学的に無関係な症例がベクトル検索に混入することを **100%防止** する。

3. **Step 3: Weighted Ranking (複合スコアリング)**
    * 絞り込まれた候補に対し、以下の要素で再ランク付けを行い、Top-K件を選定する。
    * **スコアモデル:**
      ```python
      total_score = (
          W1 * vector_similarity(文脈の一致度: pgvector) +
          W2 * entity_match_count(タグの一致数: CLEAR) - 
          W3 * numeric_distance(FIM点数や年齢の乖離)
      )
      ```
    * *補足:* `numeric_distance` は `1 - abs(target - candidate) / max_range` 等で正規化して扱う。

<!-- ### 6.1 検索戦略：ハイブリッド・リトリーバル

膨大な過去カルテから「真に参考になる症例」を見つけ出すため、2段階のフィルタリングと重み付けスコアリングを行う。

1. **Stage 1: 構造化フィルタ（SQL/Hard Filter）**
* 中間DB（PostgreSQL）に対し、SQLクエリで候補を絞り込む。
* *フィルタ条件例:* `疾患カテゴリが一致` AND `年齢 ±10歳` AND `入院時FIM合計 ±10点`。
* *目標:* 数万件 → 100件程度に絞る。


2. **Stage 2: ベクトル検索 & 複合スコアリング（Vector Search & Rerank）**
* **PostgreSQL (pgvector)** を使用。
* 絞り込まれた候補のテキストベクトルと、対象患者のテキストベクトルのコサイン類似度を計算。
    * また、あくまで例ではあるが、以下の計算式のように基づき類似度 `total_score` を算出し、上位 `K` 件を選定する。
    * **スコアモデル:**
      ```python
      total_score = (
          0.35 * disease_sim(ルールベース補正 + Embedding) +
          0.30 * function_sim(FIM等の数値距離) +
          0.15 * wish_sim(自由記述Embedding) +
          0.10 * social_sim(カテゴリ距離) +
          0.10 * plan_policy_sim(計画方針Embedding)
      )
      ```
    * **疾患類似度:** 単なるEmbeddingだけでなく、ルール（脳卒中 vs THAなら減点など）を併用する。
    * **機能評価:** FIM等は数値的な距離（`1 - abs(diff)/max`）を重視する。 -->

### 6.2 コンテキスト最適化（Context Optimization）

LLMのコンテキストウィンドウを節約し、生成精度を高めるための工夫。

* **エンティティ・ハイライト:** 検索された類似症例の全文を渡すのではなく、Phase Aで抽出された「重要エンティティ」周辺の文脈を優先的に抽出（Contextual Compression）してプロンプトに含める。
* **階層的要約:** 長期の入院記録については、日次記録ではなく「退院サマリ」や「週間要約」を優先して検索対象とする。

<!-- ### 6.2 長文コンテキスト対策（Hierarchical RAG）
電子カルテの膨大なテキストノイズを避けるため、以下の処理を行う。
* **チャンク化:** ノート単位（日付/セクション）で分割。
* **要約 (Summary SLM):** 上位チャンクを抽出後、専用のSLMで要旨（200~400トークン）を作成してから最終プロンプトに含める。
* **構造化抽出 (Extraction SLM):** FIM値、主診断、キーパーソン等は、事前に構造化データとして抽出しておく。 -->

### 6.3 外部知識ベース（Knowledge Base）
* ユーザーがPDFやテキスト（論文、マニュアル等）をアップロードできる機能。
* これらは匿名化・ベクトル化され、類似症例と同様にRAGの参照ソースとして利用される(病院ごとの方針・特徴が強く反映されると考えられるため、電子カルテとは別枠として検索してもいいかもしれません。)。

### 6.4 プロンプト構築（Context Injection）

LLMに渡すコンテキストは以下の構成とする。

* **System Prompt:** あなたはベテランの理学療法士です。以下の制約に従い、専門用語を適切に使用して計画書を作成してください。
* **Patient Context:** 対象患者の匿名化済み構造化データ（FIM推移、年齢、診断など）。
* **Reference Context (Few-Shot):** Stage 2で選ばれた類似症例の「当時の状態」と「実際に作成された計画書」のペア。
* **Prediction Context:** データサイエンスモデルが弾き出した「予後予測値」（後述）。

### 6.5 Fact Check（整合性確認）機能

* **トリガー:** ユーザーが任意のタイミングで押下する「整合性チェック」ボタンにより発動。
* **ロジック:** 軽量SLM（またはNLIモデル）を使用し、生成文の各文（Claim）が、左ペインの情報（Evidence）によって支持されるか（Entailment）、矛盾するか（Contradiction）を判定する。
* **実装:** 軽量なNLI（Natural Language Inference）モデル、または専用プロンプトを用いたLLMにより判定し、矛盾箇所をUI上で強調表示する。
---

## 7. データサイエンス・時系列予測要件

### 7.1 予測モデルの役割

LLMの「もっともらしい文章作成」を補完するため、統計的に確からしい数値予測を提供する。

* **目的変数:**
1. **退院時FIMスコア:** 各項目ごとの予測値。
2. **推定在院日数:** リハビリゴールまでの所要期間。
3. **転帰先確率:** 自宅復帰 / 施設入所 / 転院 の確率分布。



### 7.2 アルゴリズム選定

* **モデル:** **LightGBM** (勾配ブースティング決定木) を採用。
  * *理由:* テーブルデータ（構造化データ）において高い精度が出やすく、欠損値に強く、学習・推論が高速であるため。また、データサイエンスのデファクトスタンダードである勾配ブースティング決定木である。


* **特徴量 (Features):**
  * 静的因子: 年齢、性別、診断コード、発症からの期間。
  * 動的因子: 入院時FIM、直近1週間のFIM変化率（回復速度）、合併症フラグ。

* **学習 (Training):** 夜間バッチ等で定期的に全過去データを用いて学習し、モデルファイルを更新する（Optunaによるチューニングは開発時または定期メンテナンス時に実施）。
* **推論 (Inference):** 画面表示時に学習済みモデルをロードし、リアルタイム（0.01秒以下）で予測を行う。


### 7.3 出力と連携

* 予測結果（例：「退院時予測FIM: 110点、確率80%」）は、グラフとして左ペインに表示すると同時に、LLMへのプロンプトにもテキストとして挿入し、文章生成の根拠とさせる。
* *生成文例:* 「統計的予測では〇〇点までの回復が見込まれるため、歩行自立を目標設定とします。」

### 7.4 テキストデータの定量化戦略 (NLP Feature Engineering)

予測精度を向上させるため、構造化データ（FIM点数など）には現れない「患者の意欲・精神状態」を、日々の記録テキストから抽出し、LightGBMの特徴量として利用する。

#### 7.4.1 採用手法：Aspect Rule V2.2 (再帰的係り受け解析)

従来の感情分析（Sentiment Analysis）ではなく、<strong>含意関係認識（NLI）</strong>モデルを採用し、**ONNX Runtime**による量子化・高速化を行うことで、「精度」と「速度」を両立する。
* **モデル:** `mDeBERTa-v3-base-xnli` (INT8量子化済み)。
* **文単位解析 (Sentence Splitting):** 長文を1つのベクトルに丸めるのではなく、文単位（句点ごと）に分割して推論を行うことで、情報の平均化（希釈）を防ぐ。
* **多軸評価:** 「意欲（メンタル）」と「身体（フィジカル）」に対してそれぞれ異なる仮説（Hypothesis）を定義し、独立したスコアを算出する。
* **統計的特徴量:** LightGBMが学習しやすいよう、単なる平均値だけでなく「最大リスク（Min）」「情緒のブレ（Std）」などを集計する。


#### 7.4.2 検証アプローチと選定プロセス

プロトタイプにおいて、**合計13種類のNLP手法**（ルールベース、ベクトルハイブリッド、量子化AIモデル等）を実装し、以下の3点を重要指標として比較検証を行った。

1.  **身体/精神の分離:** 「右足の痛みが強い（身体）」を無視し、「リハビリを拒否（精神）」のみを抽出できるか。
2.  **リスク検知:** 「全体的には穏やかだが、一瞬だけ暴言があった」ような、平均化で消えやすいリスクを検知できるか。
3.  **実用速度:** 患者1人あたり数百件のレコードを処理しても、秒単位で完了するか。

#### 7.4.3 検証手法一覧と評価結果


| 手法カテゴリ | 手法名 | 使用モデル・ロジック | 検証結果・特性 | 採用可否 |
| --- | --- | --- | --- | --- |
| **Deep Learning** | **13. ONNX Sentence NLI** | **mDeBERTa (ONNX INT8) + 文単位バッチ**<br>文章を文単位で分割し、NLIモデルで「意欲」「身体」を個別スコア化。 | **◎ 最高精度 & 高速 (Best)**<br>「痛みはあるが意欲はある」を完璧に分離。文単位のMin/Max集計により、平均化で消える「一瞬の不穏」も検知可能。推論速度も実用圏内。 | **【採用】** |
| **係り受け解析** | 1. Aspect Rule V2.2 | GiNZA + 再帰探索 + 兄弟否定<br>係り受け構造解析により、述語否定まで追跡するルールベース。 | ○ 正確かつ軽量<br>精度は高いが、未知の表現（辞書外の言い回し）に対応できず、辞書メンテコストが高いことが課題。 | 次点 (Backup) |
| 係り受け解析 | 2. Aspect Rule V2.1 | GiNZA + 再帰探索<br>V2に加え、中継語（状態、様子）を透過するロジックを追加。 | ○ 概ね良好<br>「メンタルの状態」は拾えたが、「覇気が感じられない」等の複雑な否定構造で誤判定（Positive）したため不採用。 | 不採用 |
| 係り受け解析 | 3. Aspect Rule V2 | GiNZA + Direct/Context辞書<br>基本的な係り受け判定。 | △ 構造に弱い<br>単純な文なら正確だが、少し表現が複雑になるとターゲットを見失う（False Negative）。 | 不採用 |
| 係り受け解析 | 4. Aspect Rule V2 | GiNZA + Direct/Context辞書<br>「笑顔」等の直接表現と、「意欲」＋「低下」等の文脈表現をハイブリッドで判定。 | **◎ 正確 (Best)**<br>身体症状（Neutral）と精神症状（Negative）を明確に分離できた。否定の否定（不満はない）も正解。軽量かつ高精度。 | 不採用 |
| 係り受け解析 | 5. Aspect Rule (V1) | **GiNZA + ターゲット辞書**<br>ターゲット語（意欲等）に係る形容詞のみを評価。 | **△ 見逃し**<br>「笑顔で参加」のように、ターゲット語を伴わない自立した感情表現をNeutralとして取りこぼした。 | 不採用 |
| ベクトル解析 | 6. Aspect Rule V3 | GiNZA + Word Vector (Hybrid)<br>ターゲット語をベクトル類似度で拡張するハイブリッド手法。 | × 構造無視<br>「状態」等の抽象語が挟まるとベクトル距離が遠くなり判定不能に。また閾値調整がシビアで誤検知リスク増。 | 不採用 |
| ベクトル解析 | 7. Vector Aspect | GiNZA (Word Vector)<br>ターゲット語とのベクトル類似度で評価対象を自動拡張。 | **△ 調整困難**<br>「意欲」に近い単語を拾える利点はあるが、V1同様に見逃しが多く、類似度閾値の調整がシビア。 | 不採用 |
| 量子化AI | 8. Quantized BERT | BERT (int8 Quantization)<br>日本語感情分析モデルを動的量子化し、CPU推論を高速化。 | × 意味混同<br>処理速度はルールベースに迫るが、「足の痛み」をPositive(0.95)と誤判定する致命的な欠陥を確認。身体/精神の分離不可。 | 不採用 |
| **Deep Learning** | **9. mDeBERTa (NLI)** | **DeBERTa-v3 (含意関係)**<br>「患者は意欲的だ」という仮説との矛盾確率を計算。 | **◎ 正確**<br>V2と同等の最高精度を記録。文脈理解力は高いが、**△ 遅すぎる**<br>CPU推論で1件あたり約2秒要する。バッチ処理が現実的でない。 | 不採用 (Heavy) |
| Deep Learning | 10. BERT (Sentiment) | **BERT (感情分析モデル)**<br>一般的な日本語感情分析モデルによるポジネガ判定。 | **× 不正確**<br>「痛みが強い」等の**身体的苦痛をNegative（意欲低下）と誤判定**する傾向が強く、ノイズとなった。 | 不採用 |
| 生成AI (SLM) | 11. Ollama | LFM 2.5 instract(SFTなど未調整) プロンプトによるJSON出力指示。 | **× 危険** <br>「リハビリを拒否された」という記述に対し、**Positiveと判定する致命的なハルシネーション**を確認。臨床利用不可。 | 不採用 |
| **単純ルール** | 12. Rule (Simple) | **単語辞書マッチング**<br>文脈を無視した単純な単語カウント。 | **× 誤検知** <br>「意欲が低下」を「意欲(+1)」と判定したり、「歩行困難」を精神Negativeとしたり、精度が低い。 | 不採用 |



#### 7.4.4 採用手法 (ONNX Sentence NLI) の詳細と運用

「書き手の感情」ではなく「患者の状態（事実）」を抽出するため、NLI（Natural Language Inference）アプローチを採用した。また、LightGBMの決定木が「外れ値」や「閾値」を学習しやすいよう、特徴量エンジニアリングを強化している。

* **ロジックの概要 (Advanced Logic):**
    * **ONNX Runtimeによる高速化:** PyTorchモデルをONNX形式に変換し、さらにINT8量子化を適用。これにより、CPU環境でも推論速度を約3〜4倍に高速化し、大量データの処理を可能にした。
    * **文単位バッチ処理 (Sentence Batching):** テキストを一括処理せず、文（Sentence）ごとに分割して推論する。これにより「長いカルテの中に1文だけ含まれる拒絶」を見逃さない。
    * **意味的マッチング:** 「痛み（身体）」と「拒絶（精神）」を区別するため、それぞれ異なる仮説（Hypothesis）を用いて推論を行う。

* **LightGBMへの連携特徴量:**
    単純な平均スコアではなく、以下の統計量を算出・入力する。
    * `mental_min`: 最もネガティブだった瞬間のスコア（不穏・急変リスクの検知）。
    * `mental_std`: スコアの分散（情緒不安定さの検知）。
    * `physical_mean`: 身体的な平均状態。
    * `neg_count`: ネガティブな記述（スコア < -0.5）の出現回数。

* **利点 (Pros):**
    * **メンテナンスフリー:** ルールベースのような辞書登録作業が不要。未知の言い回し（例：「顔色が優れない」「スタッフの手を払う」）もAIが文脈から判断できる。
    * **高精度な分離:** 身体的苦痛に引きずられず、純粋な意欲・メンタル状態を数値化できる。
---

## 8. データモデル設計（Schema Design）

**PostgreSQL (pgvector)** を採用し、詳細データは **JSONB** 型で管理する。

本システムはステートレス（状態を持たない）を基本思想としますが、分析の高速化とログ管理のために2種類のデータベースを保持します。

### 8.1 中間DB（Data Warehouse / Read-Only）

電子カルテから夜間バッチ等で抽出・同期される、分析専用のデータベースです。
**原則として個人を特定できる情報（氏名、住所等）は含まず、ハッシュ化されたIDで管理します。**

* **`patients_view` (患者属性)**
  * `hash_id` (PK): 不可逆ハッシュ化された患者ID
  * `age`: 年齢（または年代）
  * `gender`: 性別
  * `diagnosis_code`: ICD-10等の疾患コード
  * `admission_date`: 入院日


* **`plan_data_store` (計画書詳細データ)**
  * 300項目を超える様式データはカラム定義せず、JSONB型で柔軟に管理する。
  * `hash_id` (FK): 患者ID
      * `doc_date`
      * `format_version`
  * **`raw_data` (JSONB):** 様式23の全項目（ADL詳細、環境因子、プログラム等）を格納。

* **`documents_view` (テキスト記録)**
  * `doc_id` (PK)
  * `hash_id` (FK): 患者ID
  * `doc_date`: 記録日
  * `doc_type`: 書類タイプ（リハビリ実施録、看護サマリ等）
  * `entities` (JSONB): GiNZA等で抽出された検索用タグ（例: `{"diagnosis": ["脳梗塞"], "symptoms": ["右片麻痺"]}`）。**GIN Index** を付与して高速検索を実現。
  * `content_vector`: 本文のベクトル埋め込み（検索用）
  * `summary_text`: 匿名化済みの要約テキスト
  * `source_type`: 'EHR', 'UPLOAD'



### 8.2 アプリケーションDB（App DB / Logs）

システムの動作ログや、ユーザーからのフィードバックを保存します。

* **`audit_logs` (監査ログ)**
  * `log_id` (PK)
  * `timestamp`: 日時
  * `user_id`: 操作したユーザー（職員ID）
  * `target_hash_id`: 閲覧/生成対象の患者ハッシュID
  * `action`: 操作内容（VIEW, GENERATE, EXPORT）


* **`feedback_data` (AI改善用)**
  * `generation_id`: 生成ID
  * `user_rating`: 評価（Good/Bad）
  * `edit_distance`: AI生成文と、人間が最終的に修正した文の差異量（モデル精度向上の指標として利用）



---

## 9. 非機能要件（Non-Functional Requirements）

### 9.1 性能・レスポンス

* **検索速度:** 中間DBに対する類似症例検索は、数万件規模のデータに対し **3秒以内** に結果を返すこと（適切なインデックス設計）。
* **生成体験:** LLMの応答はストリーミング（逐次表示）を行い、**Time To First Token（最初の文字が出るまで）を 2秒以内** に抑えること。
* **クライアント負荷:** ブラウザ側でのExcel生成やグラフ描画が、一般的な業務用PC（メモリ8GB程度）で快適に動作すること。

### 9.2 可用性・耐障害性

* **フォールバック機能:** 外部クラウドLLM（Gemini等）への接続が切断された場合でも、ローカルSLM（Ollama）に自動で切り替わり、最低限の生成機能を継続できること（将来実装）。
* **エラー耐性:** 欠損値（例：FIMスコアの一部欠落）があってもシステムエラーで停止せず、「データ不足」を明示した上で処理を続行すること。

### 9.3 保守性・拡張性

* **Docker化:** アプリケーション（Frontend, Backend, DB）は `docker-compose` コマンド一つで環境構築・起動が可能であること。
* **EHRコネクタの分離:** 電子カルテごとの仕様差異（CSVの列名など）は `Connector` クラスで吸収し、コアロジックに影響を与えない設計とすること。

* **拡張性:** 新しい様式（JSON構造の変化）にDBスキーマ変更なしで対応できること（JSONB採用の理由）。
---

## 10. 運用フロー・ユースケース


### 10.1 標準業務フロー

1. **ログイン:** 職員IDでログイン。
2. **患者選択:** 担当患者のIDを入力（またはリスト選択）。システムが中間DBからデータをロード。
3. **オンデマンド更新:** 必要に応じて「最新情報取得」ボタンを押し、直近のカルテデータを反映。
4. **プレビュー:** 左画面でFIM推移グラフや類似症例を確認。
5. **ドラフト生成:** AIが計画書案を作成。右画面でチャット形式で修正指示。
6. **Fact Check:** 「チェック」ボタンで矛盾点を確認・修正。
7. **出力:** Excel形式でダウンロードし、ブラウザを閉じる（データ破棄）。


利用者の目的と環境に応じて、システムの挙動と役割を完全に切り替える2つのモードを提供する。

### 10.1 Supervisor Mode (学習・評価モード)
* **対象:** 学生、新人療法士
* **環境:** Cloud LLM (Gemini) + ダミーデータ
* **役割:** **「指導教官」**
    1. **User Writing:** ユーザーが自力で計画書を作成する。
    2. **AI Grading:** AIが論理的整合性や具体性を採点する。
    3. **Gap Analysis:** 「ベテランならこう書く」という模範解答を提示し、ユーザー自身の記述と比較させる。
    4. **Feedback Collection:** ここで行われた「添削ログ（ユーザー案 vs 修正案）」は、Teacher Feedback Collectorにより収集され、ローカルモデルの学習データとなる。

### 10.2 Co-Pilot Mode (生成・業務モード)
* **対象:** 現場の療法士
* **環境:** Local LLM (LFM/Qwen + Multi-LoRA) + 院内データ
* **役割:** **「優秀な書記」**
    1. **Auto-Drafting:** 患者データ投入と同時に、予後予測に基づいたドラフトを高速生成する。
    2. **Adaptive Compute:** クライアントPCのスペックを自動判定し、GPUがあれば**WebLLM**で、なければ**Local Server**で推論を行う（Graceful Degradation）。


---

## 11. 開発ロードマップ（Roadmap）

まずは **Phase 1** の完遂を目指します。

### **Phase 1: MVP構築** 【最優先】

* **目標:** React画面でダミーデータを表示し、簡単なAI生成ができる状態。
* **実装項目:**
  * プロジェクトセットアップ（React + FastAPI + PostgreSQL + Docker）。
  * 中間DB（PostgreSQL）の構築と、ダミーCSVデータのインポート機能。
  * NotebookLM風の基本レイアウト（左右ペイン）の実装。
  * Backendでの個人情報ハッシュ化ロジックの実装。
  * PostgreSQL (pgvector) の構築と、JSONBを用いたスキーマ定義。
  * ダミーCSVデータのインポート機能。
  * Univer を組み込んだUIの実装。
  * ハッシュ化によるプライバシー保護ロジックの実装。


### **Phase 2: 知能化（RAG & 検索）**

* **目標:** 類似患者検索が機能し、根拠に基づいた生成ができる状態。
* **実装項目:**
  * 辞書ビルド: 万病辞書・ICF・ユーザー辞書等のコンパイルと `nlp_loader` への組み込み。
  * インジェストパイプライン: GiNZAを用いたエンティティ抽出と `negation.py` 連携の実装（DBへのタグ保存）。
  * 検索ワークフロー: **LangGraph** による `QueryAnalysis` -> `CLEAR Search` (SQL+Vector+スコアリング) -> `Generation` フローの実装。
  * 外部資料（Knowledge Base）アップロード機能。
  * 左ペインへの「参照ソース」「類似症例カード」の表示。
  * 生成文からのソース引用（ハイライト）機能の実装。



### **Phase 3: 高度化（予測 & 運用）**

* **目標:** 時系列予測やFact Checkを備えた、実運用レベルの完成度。
* **実装項目:**
  * 時系列予測モデル（LightGBM）の統合とグラフ表示。
  * Fact Checkボタンと矛盾検知ロジックの実装。
  * Excel出力（クライアントサイド生成）の実装。

---

## 12. 将来的な拡張構想 (Future Expansion)
* **プロンプト最適化:** OpenPrompt, DSPy, AdalFlow等の導入によるプロンプトエンジニアリングの自動化。
* **継続事前学習 (CPT):** 医療ドメイン知識を強化するためのLLMの追加学習。
* **マルチモーダル対応:** レントゲン画像やPDFカルテの解析・参照。
* **Agent化:** AutoGPT等を用いた、より自律的な調査・生成機能。
* **更新差分対応:** 電子カルテ更新時の差分検知と自動反映。
* **RPA連携:** APIが無い環境でのデータ取得手段の確保。
* **ユーザーサイド LLM**: 次世代ハイブリッドアーキテクチャである **Liquid LFM 2.5** を、WebAssembly/WebGPUを用いてブラウザ上で動作させるためのエンジニアリング（カーネル最適化・移植）への挑戦。さらにLoRAアダプターを切り替える技術による専門家の複数化。
* **ガードレール**: 生成された計画書の品質（必須項目の網羅性、禁止用語の有無など）を保つガードレール機能の実装。

---

## 13. 旧リポジトリからの資産継承 (Legacy Asset Migration)

旧プロトタイプ (`kcr_Rehab-Plan-Generator`) のコードベースから、ドメイン知識が詰まった以下のモジュールを「コア資産」として新システムへ移植・適合させる。

### 13.1 必須資産 (Core Assets)
修正なし、またはデータ形式の変換のみで採用するモジュール。

| カテゴリ | 対象ファイル | 移行戦略・用途 |
| :--- | :--- | :--- |
| **データ定義** | `app/services/excel/mappings.py` | **【JSON化して採用】**<br>様式23の300以上のセル座標定義。JSONマスタに変換し、Frontend/Backend共通の座標定義として利用する。 |
| **出力雛形** | `template.xlsx` | **【そのまま採用】**<br>Excel出力のベーステンプレート。 |
| **NLPロジック** | `app/services/extraction/negation.py` | **【そのまま採用】**<br>GiNZAを用いた否定判定（「〜なし」「〜認めず」の検知）ロジック。**Phase 2: Hybrid CLEAR検索** の精度担保に不可欠。 |
| **辞書データ** | `user_dic.csv` | **【拡張利用】**<br>独自のリハビリ用語辞書。これをベースにICFコードやFIM用語を追加し、SudachiPy用のカスタム辞書(L3)を構築する。 |
| **プロンプト** | `app/services/llm/prompts.py` | **【テンプレート移植】**<br>「専門用語を避ける」「患者への配慮」など調整済みの指示文を、**LangChain PromptTemplate** に移植する。 |

### 13.2 参照・再利用資産 (Reference Assets)
ロジックやアルゴリズムを新アーキテクチャ（FastAPI/LangGraph）に合わせて書き換えて利用するモジュール。

| カテゴリ | 対象ファイル | 移行戦略・用途 |
| :--- | :--- | :--- |
| **バリデーション** | `app/models/plan.py` | **【ロジック再利用】**<br>各項目のデータ型（bool/str/int）定義を、新システムの **Pydanticモデル（スキーマ）** 作成時の設計図として使用する。 |
| **Ingest予備** | `app/services/llm/patient_info_parser.py` | **【予備実装】**<br>正規表現による非構造化テキスト解析ロジック。API/CSV連携ができない場合のバックアップ手段として `Ingest Pipeline` に組み込む。 |
| **Excel生成** | `app/services/excel/writer.py` | **【仕様参照】**<br>Python (`openpyxl`) コードは使用しないが、「性別を記号に変換する」等の**書き込み仕様**を、Frontend (`Univer/ExcelJS`) 実装時に参照する。 |
| **RAG設定** | `Rehab_RAG/rag_config.yaml` | **【設定参照】**<br>チャンクサイズや検索パラメータのベース値として利用する。 |


<!-- フェーズを 「A. データ構築（夜間バッチ）」 と 「B. 利用（リアルタイム生成）」 の2つに分けて考える。

A. データ構築フェーズ（夜間バッチ / 初回構築 / ユーザーによる構築呼び出し）

電子カルテのデータを、「検索に使える形」に加工してPostgreSQLに格納するプロセスです。

Step 1: データ抽出 (Extraction)

電子カルテDBから、過去の患者データをCSV等で抽出します。

抽出項目:

基本情報: 患者ID、年齢、疾患名、発症日、転帰（自宅復帰など）。

評価データ: FIM得点（運動/認知）、麻痺レベル。

テキストデータ:

日々の記録: 看護記録、リハビリ実施録（→ ONNXでスコア化）。

社会背景: HOPE、職業、家族構成、家屋環境（→ Vector化）。

過去の計画書: 実際に作成された計画書のテキスト（→ 参照用）。

Step 2: 特徴量エンジニアリング (ONNX & NLP)

ここが最も重要な「データの付加価値化」プロセスです。

メンタル/身体スコア化 (ONNX)

日々の記録テキストを文単位に分割し、mDeBERTa (ONNX) で推論。

mental_min（最大リスク）、mental_mean（平均意欲）、physical_mean（身体状態）を算出。

結果: 「不穏リスクあり」「意欲高い」といった数値タグが付く。

社会背景のベクトル化 (Embedding)

社会背景テキスト（HOPE、職業等）のみを結合し、Embeddingモデル（例: intfloat/multilingual-e5-base）でベクトル化。

結果: [0.12, -0.5, ...] のような768次元ベクトルが生成される。

キーワード抽出 (GiNZA)

テキストから重要語句（「右片麻痺」「独居」など）を抽出し、検索用タグとして保存。

Step 3: データベース格納 (Load)

加工したデータを PostgreSQL (pgvector) に保存します。

Patients Table:

id, age, disease, total_fim (基本情報)

mental_min, mental_std (ONNXスコア)

social_vector (社会背景ベクトル)

plan_text (過去の計画書正解データ)



あとは、これらのデータからLightGBMを学習させて、患者の経過予測モデルを作っておく。



B. 利用フェーズ（リアルタイム生成）

セラピストが画面で「この患者の計画書を作りたい」と操作した時の動きです。

Step 1: ターゲット患者の解析 (Input Analysis)

入力: 担当患者のID、または入力されたばかりの評価情報。

処理: 対象患者のカルテ情報を取得し、Step Aと同じロジックで「メンタルスコア算出」と「社会背景ベクトル化」をリアルタイム実行します（ONNXが高速なので一瞬です）。



そして、LightGBMでの予測もここで行う。



Step 2: 類似患者の検索 (Hybrid Search)

ここで SQL × Vector の2段階検索 を行います。

SQL絞り込み (Hard Filter):

「疾患が一致」かつ「FIM点数が ±10点」かつ「メンタルスコアが近い（±0.2）」患者をDBから検索。

効果: 医学的・精神的に似ている患者 50〜100人がヒット。

ベクトル再ランク (Soft Rerank):

ヒットした患者の social_vector と、ターゲット患者のベクトルの類似度（Cosine Similarity）を計算。

類似度が高い順にソートし、Top 3 を選定。

効果: その中で「元大工」「独居」など背景が似ている人が選ばれる。

Step 3: プロンプト構築 (Context Construction)

LLM（GeminiやOllama）に渡す命令文を作ります。

System: 「あなたはベテラン療法士です...」

Context (類似症例):

検索されたTop 3患者の「当時の状態」と「実際に作られた計画書」を提示。

例: 「参考症例A（元大工、意欲高）では、『屋外歩行訓練』が設定されました。」

Target (対象患者):

「今回の患者は、これらと似ていますが、特に『夜間の不穏（ONNXスコア低）』があります。」



(予測):

予測では、このような予測になります。:信頼度による3段階の出し分けを検討。LightGBMは予測クラスに対する確率（Probability）を出力でプロンプトに加えるのか否かを判断(前提・参考・使わない)。



Instruction:

「参考症例を活かしつつ、夜間リスクに配慮した計画書を作成してください。」



Step 4: 生成と提示 (Generation)

LLMが計画書ドラフトを生成。

画面（Univerスプレッドシート等）に表示。

ユーザーが確認・修正し、完成。

まとめ：システムフロー図

コード スニペット



「医学的な正確さ（SQL）」と「個別の寄り添い（Vector）」を両立させつつ、ONNXの高速性を活かした実用的なレスポンスタイムを実現させたい。




あとは、使うライブラリはLiteLLM(LiteLLMと'litellm[proxy]'を使うかも)、LangGraph(LangChainは使わない。)を使いたい。

将来的にはArize Phoenix、Unstructuredを使う感じ。 -->

